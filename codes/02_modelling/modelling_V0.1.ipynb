{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper Segmentation\n",
    "\n",
    "Network backbone is a Resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import skimage\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\") # Directory to save logs and trained model\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\") # Local path to trained weights file\n",
    "\n",
    "if not os.path.exists(COCO_MODEL_PATH): # Download COCO trained weights\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesConfig(Config):\n",
    "    NAME = \"newspapers\"\n",
    "    GPU_COUNT = 1 # Train on 1 GPU and 8 images per GPU.\n",
    "    IMAGES_PER_GPU = 8 # Batch size is 8 (GPUs * images/GPU).\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "    \n",
    "    IMAGE_RESIZE_MODE = 'square' #square or pad64 or crop\n",
    "    \n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels to extract low resolution \n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "    \n",
    "    STEPS_PER_EPOCH = 100  # Use a small epoch since the data is simple\n",
    "    VALIDATION_STEPS = 5 # use small validation steps since the epoch is small\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=12):\n",
    "    \"\"\"Return a Matplotlib Axes\"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newspaperDataset(utils.Dataset):\n",
    "    \n",
    "    def load_data(self, dataset_dir, subset):\n",
    "        \"\"\"\n",
    "        Load a subset of the newspaper dataset.\n",
    "            \n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "\n",
    "        self.add_class(\"newspaper\", 0, \"article\")\n",
    "        self.add_class(\"newspaper\", 1, \"non-article\")\n",
    "        self.add_class(\"newspaper\", 2, \"title\")\n",
    "\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"annotations.json\")))\n",
    "        filenames = list(annotations.keys())\n",
    "        annotations = list(annotations.values())\n",
    "\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            shapes = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            classes = [r['region_attributes']['label'] for r in a['regions'].values()]\n",
    "\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"newspaper\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                shapes=shapes,\n",
    "                classes=classes)\n",
    "            \n",
    "        return filenames\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"newspaper\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        info = self.image_info[image_id]\n",
    "        classes = info['classes']\n",
    "        \n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"shapes\"])],\n",
    "                        dtype=np.uint8)\n",
    "        \n",
    "        for i, p in enumerate(info[\"shapes\"]):\n",
    "            if p['name'] == 'polygon':\n",
    "                rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "                mask[rr, cc, i] = 1\n",
    "                \n",
    "            if p['name'] == 'rectangle':\n",
    "                start = (int(p['ymin']),int(p['xmin']))\n",
    "                extent = (int(p['ymax']),int(p['xmax']))\n",
    "                \n",
    "                rr, cc = skimage.draw.rectangle(start=start, extent=extent, shape=mask.shape)\n",
    "                mask[rr, cc, i] = 1\n",
    "                \n",
    "        class_ids = np.array([self.class_names.index(s) for s in classes])\n",
    "        \n",
    "        return mask, class_ids\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"newspaper\":\n",
    "            return info[\"newspaper\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_DIR = os.path.join(ROOT_DIR, \"datasets/newspaper/\")\n",
    "\n",
    "dataset = newspaperDataset()\n",
    "data_names = dataset.load_data(data_DIR, \"train\")\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.image_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.Dataset -> instance -> newspaperDataset()\n",
    "\n",
    "newspaperDataset().image_ids\n",
    "newspaperDataset().image_info\n",
    "newspaperDataset().class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" ============= Display some sample dataset informations =============\"\n",
    "\n",
    "for ids in dataset.image_ids[:1]:\n",
    "    mask, class_ids = dataset.load_mask(ids)\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    \n",
    "    image_path = data_DIR+'/train/'+data_names[ids]\n",
    "    image = skimage.io.imread(image_path)\n",
    "\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)\n",
    "    visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names,figsize=(5, 5))\n",
    "    \n",
    "    image, window, scale, padding, _ = utils.resize_image(\n",
    "        image, \n",
    "        min_dim=config.IMAGE_MIN_DIM, \n",
    "        max_dim=config.IMAGE_MAX_DIM,\n",
    "        mode='square')\n",
    "    mask = utils.resize_mask(mask, scale, padding)\n",
    "    \n",
    "    log(\"image\", image)\n",
    "    log(\"mask\", mask)\n",
    "    \n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "    visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names,figsize=(5, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
