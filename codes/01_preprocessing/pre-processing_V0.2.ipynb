{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper Segmentation\n",
    "\n",
    "#### This scipt is recommended to be used for both pre-processing and post-processing methods\n",
    "\n",
    "Following functions and methods are implemented in order to produce segmentation within the newspapers and further improvements will be added in future.\n",
    "\n",
    "Thresholding(Otsu's, Basic Segmentation)\n",
    "Denoising\n",
    "Dilation\n",
    "Run Length Smoothing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pythonRLSA import rlsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_images(filepath:str, mode:str, write=(False,False)):\n",
    "    files = sorted(os.listdir(filepath), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    print(\"Total_nos_images ==>\",len(files))\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        data = [cv2.imread(filepath+name, cv2.IMREAD_GRAYSCALE) for name in files]\n",
    "    else:\n",
    "        data = [cv2.imread(filepath+name) for name in files]\n",
    "        \n",
    "    if write[0]:\n",
    "        path = write[1]\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        for ind,each in enumerate(data):\n",
    "            name = path+'img_'+str(ind+1)\n",
    "            cv2.imwrite(name+\".png\", each)\n",
    "    return files,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(orgList, filepath:str, filename:None, custom_resolution:tuple):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "        \n",
    "    custom_height, custom_width = custom_resolution\n",
    "    \n",
    "    if custom_height > custom_width:\n",
    "        resizedArr = np.empty((len(orgList), custom_height, custom_width, 3), dtype='float32')\n",
    "\n",
    "        for ind, image in enumerate(orgList):\n",
    "            img = image.astype('float32')\n",
    "            resized = cv2.resize(img, (custom_width, custom_height))\n",
    "            resizedArr[ind] = resized\n",
    "            if filename:\n",
    "                filename_r = 'resized_'+str(ind)+\".png\"\n",
    "                cv2.imwrite(filepath+filename_r, resized)\n",
    "            \n",
    "    return resizedArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(imgArr, filepath:str, filename:str, params:tuple):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "    \n",
    "    methods = {'binary': cv2.THRESH_BINARY,\n",
    "               'binary_inv': cv2.THRESH_BINARY_INV,\n",
    "               'otsu': cv2.THRESH_OTSU}\n",
    "    \n",
    "    copy = imgArr.copy()\n",
    "    gray = cv2.cvtColor(imgArr, cv2.COLOR_BGR2GRAY) #grayscale conversion\n",
    "\n",
    "    if params[2] in list(methods.keys()):\n",
    "        ret,thres = cv2.threshold(gray, params[0], params[1], methods[params[2]])\n",
    "    else:\n",
    "        print('Thresholding method not found from ',list(methods.keys()))\n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, thres)\n",
    "\n",
    "    return thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_denoised(imgArr, filepath:str, filename:str, params:tuple):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "        \n",
    "    copy = imgArr.copy()\n",
    "    gray = cv2.cvtColor(imgArr, cv2.COLOR_BGR2GRAY)\n",
    "    denoised = cv2.fastNlMeansDenoising(imgArr,None,\n",
    "                                        params[0],params[1],params[2])\n",
    "    \n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, denoised)\n",
    "\n",
    "    return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_morphology(imgArr, filepath:str, filename:str, params:tuple):\n",
    "    if filepath is not None:\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "            print('\\nCreating directory ->',filepath)\n",
    "    \n",
    "    copy = imgArr.copy()\n",
    "    if params[0] == 'dilation':\n",
    "        size = params[1]\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, size)\n",
    "        dilated = cv2.dilate(imgArr, kernel, iterations=params[2])\n",
    "        output = dilated\n",
    "        \n",
    "    if params[0] == 'erosion':\n",
    "        size = params[1]\n",
    "        kernel = np.ones((size,size), dtype=np.float32)\n",
    "        eroded = cv2.erode(imgArr, kernel)\n",
    "        output = eroded\n",
    "        \n",
    "    if filename:   \n",
    "        cv2.imwrite(filepath+filename, output) \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_RLSA_hor(imgArr, val:int, filepath:str, filename:str):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "\n",
    "    x, y = imgArr.shape[0],imgArr.shape[1]\n",
    "    value = max(math.ceil(x/100),math.ceil(y/100))+val\n",
    "\n",
    "    mask = rlsa.rlsa(imgArr, True, False, value)\n",
    "\n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def perform_RLSA_ver(imgArr, val:int, filepath:str, filename:str):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "\n",
    "    x, y = imgArr.shape[0],imgArr.shape[1]\n",
    "    value = max(math.ceil(x/100),math.ceil(y/100))+val\n",
    "\n",
    "    mask = rlsa.rlsa(imgArr, False, True, value)\n",
    "\n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, mask)\n",
    "        \n",
    "    return mask\n",
    "\n",
    "def get_RLSA_final(imgArr1, imgArr2, filepath:str, filename:str):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "\n",
    "    rlsa_f = cv2.bitwise_or(imgArr1,imgArr2)\n",
    "    rlsa_f = cv2.bitwise_not(rlsa_f)\n",
    "\n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, rlsa_f)\n",
    "\n",
    "    return rlsa_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_masks(imgList, orgList, filepath:str, filter_height = (True, [0,0]), filter_width = (False, [0,0]), morph_params = False, no_fill = False, bbox = True):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "    \n",
    "    if no_fill:\n",
    "        thickness = 1\n",
    "    else:\n",
    "        thickness = -1\n",
    "    \n",
    "    final_bbox = dict()\n",
    "    \n",
    "    for ind in range(0,len(imgList)):\n",
    "        temp_bbox = []\n",
    "        contours, hierarchy = cv2.findContours(imgList[ind], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        mask2 = np.ones(orgList[ind].shape, dtype=\"uint8\") * 0\n",
    "                \n",
    "        title = [contour for contour in contours if cv2.boundingRect(contour)[3] > filter_height[1][0]]\n",
    "        title_heights = [cv2.boundingRect(contour)[3] for contour in contours if cv2.boundingRect(contour)[3] > filter_height[1][0]]\n",
    "        title_widths = [cv2.boundingRect(contour)[2] for contour in contours if cv2.boundingRect(contour)[3] > filter_width[1][0]]\n",
    "        \n",
    "        avgwidth = sum(title_widths)/len(title_widths)\n",
    "        \n",
    "        cnt = 0\n",
    "        for cnts in title:\n",
    "            area = cv2.contourArea(cnts)\n",
    "            peri = cv2.arcLength(cnts, True)\n",
    "            epsilon = 0.001*peri\n",
    "            approx = cv2.approxPolyDP(cnts, epsilon, True)\n",
    "            cnt+=1\n",
    "            bbox_rect = cv2.boundingRect(approx)\n",
    "            [x, y, w, h] = bbox_rect\n",
    "            \n",
    "            if filter_height[0]:\n",
    "                if h < filter_height[1][1]:\n",
    "                    title = orgList[ind][y: y+h, x: x+w]\n",
    "                    if bbox:\n",
    "                        cv2.rectangle(mask2, (x,y),(x+w,y+h), (255, 255, 255), thickness)\n",
    "                        mask = apply_morphology(mask2, None, False, morph_params)\n",
    "                    else:\n",
    "                        cv2.drawContours(mask2, [approx], -1, (255, 255, 255), thickness)\n",
    "                    temp_bbox.append(bbox_rect)\n",
    "                    \n",
    "            if filter_width[0]:\n",
    "                if w > filter_width[1][1]*avgwidth:\n",
    "                    title = orgList[ind][y: y+h, x: x+w]\n",
    "                    if bbox:\n",
    "                        cv2.rectangle(mask2, (x,y),(x+w,y+h), (255, 255, 255), thickness)\n",
    "                        mask = apply_morphology(mask2, None, False, morph_params)\n",
    "                    else:\n",
    "                        cv2.drawContours(mask2, [approx], -1, (255, 255, 255), thickness)\n",
    "                    temp_bbox.append(bbox_rect)\n",
    "                \n",
    "        cv2.imwrite(filepath+'/result_'+str(ind)+'.png', mask)\n",
    "        final_bbox[ind] = temp_bbox\n",
    "        \n",
    "    return final_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_masks(imgList, filepath:str, title_bboxes, filter_height = (True, 0), filter_width = (False, 0), morph_params = False, no_fill = False, bbox = True):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "    \n",
    "    if no_fill:\n",
    "        thickness = 1\n",
    "    else:\n",
    "        thickness = -1\n",
    "    \n",
    "    final_bbox = dict()\n",
    "    \n",
    "    for ind in range(0,len(imgList)):\n",
    "        temp_bbox = []\n",
    "        \n",
    "        for bbx in title_bboxes[ind]:\n",
    "            (x,y,w,h) = bbx\n",
    "            imgList[ind][y: y+h, x: x+w] = 0\n",
    "            \n",
    "        dilated = apply_morphology(imgList[ind], None, False, morph_params)        \n",
    "        mask1 = np.ones(imgList[ind].shape, dtype=\"uint8\") * 0\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "        widths = [cv2.boundingRect(contour)[2] for contour in contours]\n",
    "        \n",
    "        avgheight = 26.54 #calculated on a sample using formula <--avgheight = sum(heights)/len(heights)-->\n",
    "        avgwidth = 54.64 #calculated on a sample using formula <--avgwidth = sum(widths)/len(widths)-->\n",
    "        \n",
    "        for cnts in contours:\n",
    "            area = cv2.contourArea(cnts)\n",
    "            peri = cv2.arcLength(cnts, True)\n",
    "            epsilon = 0.001*peri\n",
    "            approx = cv2.approxPolyDP(cnts, epsilon, True)\n",
    "            bbox_rect = cv2.boundingRect(approx)\n",
    "            [x, y, w, h] = bbox_rect\n",
    "            \n",
    "            if filter_height[0] and filter_width[0]:\n",
    "                if h > filter_height[1]*avgheight and w > filter_width[1]*avgwidth:\n",
    "                    if bbox:\n",
    "                        cv2.rectangle(mask1, (x,y),(x+w,y+h), (255, 255, 255), thickness)\n",
    "                    else:\n",
    "                        cv2.drawContours(mask1, [approx], -1, (255, 255, 255), thickness)\n",
    "                        \n",
    "                    temp_bbox.append(bbox_rect)\n",
    "                \n",
    "        cv2.imwrite(filepath+'/result_'+str(ind)+'.png', mask1)\n",
    "        final_bbox[ind] = temp_bbox\n",
    "        \n",
    "    return final_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bboxes(dstImg, contour_params=(cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)):\n",
    "    title_bboxes = dict()\n",
    "    for ind in range(0,len(dstImg)):\n",
    "        bboxes = list()\n",
    "        contours, hierarchy = cv2.findContours(dstImg[ind], contour_params[0], contour_params[1])\n",
    "        for cnts in contours:\n",
    "            peri = cv2.arcLength(cnts, True)\n",
    "            epsilon = 0.001*peri\n",
    "            approx = cv2.approxPolyDP(cnts, epsilon, True)\n",
    "            bbox_rect = cv2.boundingRect(approx)\n",
    "            bboxes.append(bbox_rect)\n",
    "        title_bboxes[ind] = bboxes\n",
    "        \n",
    "    return title_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bbox(img, filepath:str, filename:str, bboxes, color=(180, 180, 180)):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "        \n",
    "    for cnts in bboxes:\n",
    "        x,y,w,h = cnts\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, -1)\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0, 0, 0), 1)\n",
    "        \n",
    "    cv2.imwrite(filepath+filename, img)\n",
    "    return img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n",
      "['resized_17.png', 'resized_18.png', 'resized_19.png', 'resized_20.png', 'resized_21.png', 'resized_22.png', 'resized_23.png', 'resized_24.png', 'resized_25.png', 'resized_26.png', 'resized_27.png', 'resized_28.png', 'resized_29.png', 'resized_30.png', 'img_2018-02-02-10-C.png', 'img_2018-02-02-26-C.png', 'img_2018-02-02-37-C.png', 'Financial_Exp_30_Sep_2020_page-0005.jpg', 'Financial_Exp_30_Sep_2020_page-0007.jpg', 'Financial_Exp_30_Sep_2020_page-0010.jpg', 'Financial_Exp_30_Sep_2020_page-0014.jpg']\n"
     ]
    }
   ],
   "source": [
    "path = 'Images/'\n",
    "fl,data = read_all_images(path, mode=False) #write=(True,path)\n",
    "print(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_r = \"Outputs/resized/\"\n",
    "org = prepare_dataset(data, filepath_r, True, (1507,960))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting RLSA final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [01:26,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "filepath_1 = \"Outputs/denoised/\"\n",
    "filepath_2 = \"Outputs/threshold/\"\n",
    "\n",
    "params_denoise = (10,7,21) # filter strength, templateWindowSize, searchWindowSize\n",
    "params_thres = (200, 255, 'otsu')\n",
    "\n",
    "filepath_r = \"Outputs/resized/\"\n",
    "_,res_data = read_all_images(filepath_r, mode=None)\n",
    "\n",
    "for ind,imgArr in tqdm(enumerate(res_data)):\n",
    "    filename_1 = 'denoised_'+str(ind)+\".png\"\n",
    "    filename_2 = 'thres_'+str(ind)+\".png\"\n",
    "    \n",
    "    denoised = make_denoised(imgArr,filepath_1,filename_1,params_denoise)\n",
    "    thres = apply_threshold(imgArr,filepath_2,filename_2,params_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLSA Horizontal - Title/Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [03:43, 10.64s/it]\n"
     ]
    }
   ],
   "source": [
    "filepath_2 = \"Outputs/threshold/\"\n",
    "filepath_3 = \"Outputs/title_RLSA/RLSA_h/\"\n",
    "thres_data = read_all_images(filepath_2, mode='binary')\n",
    "\n",
    "for ind,imgArr in tqdm(enumerate(thres_data[1])):\n",
    "    filename_3 = 'rlsa_h_'+str(ind)+\".png\"\n",
    "    rlsa_h = perform_RLSA_hor(imgArr,10,filepath_3,filename_3)\n",
    "    rlsa_h = perform_RLSA_hor(imgArr,100,\"Outputs/RLSA_h/\",filename_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLSA Vertical - Title/Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [04:22, 12.51s/it]\n"
     ]
    }
   ],
   "source": [
    "filepath_2 = \"Outputs/threshold/\"\n",
    "filepath_4 = \"Outputs/title_RLSA/RLSA_v/\"\n",
    "thres_data = read_all_images(filepath_2, mode='binary')\n",
    "\n",
    "for ind,imgArr in tqdm(enumerate(thres_data[1])):\n",
    "    filename_4 = 'rlsa_v_'+str(ind)+\".png\"\n",
    "    rlsa_v = perform_RLSA_ver(imgArr,10,filepath_4,filename_4)\n",
    "    rlsa_v = perform_RLSA_ver(imgArr,100,\"Outputs/RLSA_v/\",filename_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLSA final - Title/Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n",
      "Total_nos_images ==> 21\n",
      "Total_nos_images ==> 21\n",
      "Total_nos_images ==> 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 16.80it/s]\n"
     ]
    }
   ],
   "source": [
    "filepath_5 = \"Outputs/title_RLSA/RLSA_f/\"\n",
    "_,data_h = read_all_images(filepath_3,mode=False)\n",
    "_,data_v = read_all_images(filepath_4,mode=False)\n",
    "\n",
    "_,data_h_1 = read_all_images(\"Outputs/RLSA_h/\",mode=False)\n",
    "_,data_v_1 = read_all_images(\"Outputs/RLSA_v/\",mode=False)\n",
    "\n",
    "for ind in tqdm(range(0,len(data_h))):\n",
    "    filename_5 = 'rlsa_f_'+str(ind)+\".png\"\n",
    "    get_RLSA_final(data_h[ind],data_v[ind],filepath_5,filename_5)\n",
    "    get_RLSA_final(data_h_1[ind],data_v_1[ind],\"Outputs/RLSA_f/\",filename_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Title masks from RLSA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    }
   ],
   "source": [
    "filepath_5 = \"Outputs/title_RLSA/RLSA_f/\"\n",
    "_,data_rlsa = read_all_images(filepath_5, mode='binary')\n",
    "\n",
    "title_mask_path = 'Outputs/title_masks/'\n",
    "final_bbox = get_title_masks(data_rlsa, data_rlsa, title_mask_path, \n",
    "                                             filter_height = (True, [9.055, 37.949]),\n",
    "                                             morph_params = ('dilation', (6,1), 2),\n",
    "                                             no_fill = False, bbox = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    }
   ],
   "source": [
    "filepath_6 = \"Outputs/title_masks/\"\n",
    "_,data_rlsa = read_all_images(filepath_6, mode='binary')\n",
    "\n",
    "title_mask_path = 'Outputs/title_masks_f/'\n",
    "final_bbox = get_title_masks(data_rlsa, data_rlsa, title_mask_path,\n",
    "                                            filter_height = (False, [0,0]),\n",
    "                                            filter_width = (True, [0,0.5]),\n",
    "                                            morph_params = ('dilation', (2,5), 1),\n",
    "                                            no_fill = False, bbox = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract title bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    }
   ],
   "source": [
    "filepath_7 = \"Outputs/title_masks_f/\"\n",
    "_,title_masks = read_all_images(filepath_7, mode='binary')\n",
    "\n",
    "title_bboxes = extract_bboxes(title_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Content masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    }
   ],
   "source": [
    "filepath_8 = \"Outputs/RLSA_f/\"\n",
    "_,data_rlsa = read_all_images(filepath_8, mode='binary')\n",
    "\n",
    "content_mask_path = 'Outputs/content_masks_f/'\n",
    "final_bbox = get_content_masks(data_rlsa, \n",
    "                               content_mask_path, title_bboxes,\n",
    "                               filter_height = (True, 0.25),\n",
    "                               filter_width = (True, 0.25),\n",
    "                               morph_params = ('dilation', (1,3), 2),\n",
    "                               no_fill = False, bbox = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract content bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    }
   ],
   "source": [
    "filepath_9 = \"Outputs/content_masks_f/\"\n",
    "_,content_masks = read_all_images(filepath_9, mode='binary')\n",
    "\n",
    "content_bboxes = extract_bboxes(content_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = copy.deepcopy(org)\n",
    "\n",
    "final_path = \"Results/\"\n",
    "for ind in range(len(original)):\n",
    "    final_filename = \"Result\"+str(ind)+\".png\"\n",
    "    out = apply_bbox(original[ind], final_path, final_filename, title_bboxes[ind], (180, 180, 180))\n",
    "    apply_bbox(out, final_path, final_filename, content_bboxes[ind], (180, 180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
