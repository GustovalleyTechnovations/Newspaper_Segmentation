{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper Segmentation\n",
    "\n",
    "#### This scipt is recommended to be used for both pre-processing and post-processing methods\n",
    "\n",
    "Following functions and methods are implemented in order to produce segmentation within the newspapers and further improvements will be added in future.\n",
    "\n",
    "Thresholding(Otsu's, Basic Segmentation)\n",
    "Denoising\n",
    "Dilation\n",
    "Run Length Smoothing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "from pythonRLSA import rlsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_images(filepath:str, mode:str, write=(False,False)):\n",
    "    files = sorted(os.listdir(filepath), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    print(\"Total_nos_images ==>\",len(files))\n",
    "    \n",
    "    if mode == 'binary':\n",
    "        data = [cv2.imread(filepath+name, cv2.IMREAD_GRAYSCALE) for name in files]\n",
    "    else:\n",
    "        data = [cv2.imread(filepath+name) for name in files]\n",
    "        \n",
    "    if write[0]:\n",
    "        path = write[1]\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        for ind,each in enumerate(data):\n",
    "            path = path+str(ind)\n",
    "            cv2.imwrite(path+\".png\", each)\n",
    "    return files,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 21\n"
     ]
    }
   ],
   "source": [
    "path = 'images/collected/'\n",
    "fl,data = read_all_images(path, mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper1.jpg', 'paper2.png', 'paper3.jpg', 'paper4.jpeg', 'paper5.jpg', 'paper7.jpg', 'paper8.jpg', 'paper9.jpg', 'paper10.jpg', 'paper11.jpg', 'paper12.jpg', 'paper13.jpg', 'paper14.jpg', 'paper15.jpg', 'paper16.jpg', 'paper17.jpg', 'paper18.jpg', 'paper19.jpg', 'paper20.jpg', 'paper21.jpg', 'paper22.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(imgArr, filepath:str, filename:str, params:tuple):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "    \n",
    "    methods = {'binary': cv2.THRESH_BINARY,\n",
    "               'binary_inv': cv2.THRESH_BINARY_INV,\n",
    "               'otsu': cv2.THRESH_OTSU}\n",
    "    \n",
    "    copy = imgArr.copy()\n",
    "    gray = cv2.cvtColor(imgArr, cv2.COLOR_BGR2GRAY) #grayscale conversion\n",
    "\n",
    "    if params[2] in list(methods.keys()):\n",
    "        ret,thres = cv2.threshold(gray, params[0], params[1], methods[params[2]])\n",
    "    else:\n",
    "        print('Thresholding method not found from ',list(methods.keys()))\n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, thres)\n",
    "    print('\\nApplied threshold..')\n",
    "    \n",
    "    return thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_denoised(imgArr, filepath:str, filename:str, params:tuple):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "        \n",
    "    copy = imgArr.copy()\n",
    "    gray = cv2.cvtColor(imgArr, cv2.COLOR_BGR2GRAY)\n",
    "    denoised = cv2.fastNlMeansDenoising(imgArr,None,\n",
    "                                        params[0],params[1],params[2])\n",
    "    \n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, denoised)\n",
    "    print('\\nApplied denoising..')\n",
    "    return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_morphology(imgArr, filepath:str, filename:str, params:tuple):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "        \n",
    "    copy = imgArr.copy()\n",
    "    if params[0] == 'dilation':\n",
    "        size = params[1]\n",
    "        kernel = np.ones((size,size), dtype=np.float32)\n",
    "        dilated = cv2.dilate(imgArr, kernel)\n",
    "        output = dilated\n",
    "        print('\\nApplied dilation..')\n",
    "        \n",
    "    if params[0] == 'erosion':\n",
    "        size = params[1]\n",
    "        kernel = np.ones((size,size), dtype=np.float32)\n",
    "        eroded = cv2.erode(imgArr, kernel)\n",
    "        output = eroded\n",
    "        print('\\nApplied erosion..')\n",
    "        \n",
    "    if filename:   \n",
    "        cv2.imwrite(filepath+filename, output) \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_RLSA_hor(imgArr, filepath:str, filename:str):\n",
    "#     try:\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "\n",
    "    x, y = imgArr.shape[0],imgArr.shape[1]\n",
    "    value = max(math.ceil(x/100),math.ceil(y/100))+20\n",
    "\n",
    "    mask = rlsa.rlsa(imgArr, True, False, value)\n",
    "\n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def perform_RLSA_ver(imgArr, filepath:str, filename:str):\n",
    "#     try:\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "\n",
    "    x, y = imgArr.shape[0],imgArr.shape[1]\n",
    "    value = max(math.ceil(x/100),math.ceil(y/100))+20\n",
    "\n",
    "    mask = rlsa.rlsa(imgArr, False, True, value)\n",
    "\n",
    "    if filename:\n",
    "        cv2.imwrite(filepath+filename, mask)\n",
    "        \n",
    "        return mask\n",
    "\n",
    "def get_RLSA_final(imgArr1, imgArr2, filepath:str, filename:str):\n",
    "    try:\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "            print('\\nCreating directory ->',filepath)\n",
    "\n",
    "        rlsa_f = cv2.bitwise_or(imgArr1,imgArr2)\n",
    "        rlsa_f = cv2.bitwise_not(rlsa_f)\n",
    "\n",
    "        if filename:\n",
    "            cv2.imwrite(filepath+filename, rlsa_f)\n",
    "\n",
    "        return rlsa_f\n",
    "    except:\n",
    "        print('\\nerrorjgv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(imgList, orgList, filepath:str, no_fill = False):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        print('\\nCreating directory ->',filepath)\n",
    "        \n",
    "    if no_fill:\n",
    "        thickness = 1\n",
    "    else:\n",
    "        thickness = -1\n",
    "        \n",
    "    for ind in range(0,len(data_dil)):\n",
    "        contours, hierarchy = cv2.findContours(imgList[ind], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = 0\n",
    "\n",
    "        for cnts in contours:\n",
    "            peri = cv2.arcLength(cnts, True)\n",
    "            epsilon = 0.001*peri\n",
    "            approx = cv2.approxPolyDP(cnts, epsilon, True)\n",
    "            cnt+=1\n",
    "            cv2.drawContours(orgList[ind], [approx], -1, (0, 0, 255), thickness)\n",
    "\n",
    "        cv2.imwrite(filepath+'/final_result_'+str(ind)+'.png', orgList[ind])\n",
    "        cv2.imshow(\"show\",orgList[ind])\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applied denoising..\n",
      "\n",
      "Applied threshold..\n",
      "\n",
      "Applied denoising..\n",
      "\n",
      "Applied threshold..\n"
     ]
    }
   ],
   "source": [
    "filepath_1 = \"test_images/denoised/\"\n",
    "filepath_2 = \"test_images/threshold/\"\n",
    "filepath_3 = \"test_images/RLSA_h/\"\n",
    "filepath_4 = \"test_images/RLSA_v/\"\n",
    "filepath_5 = \"test_images/RLSA_f/\"\n",
    "\n",
    "params_denoise = (10,7,21) # filter strength, templateWindowSize, searchWindowSize\n",
    "params_thres = (200, 255, 'otsu')\n",
    "\n",
    "for ind,imgArr in enumerate(data):\n",
    "    filename_1 = 'denoised_'+str(ind)+\".png\"\n",
    "    filename_2 = 'thres_'+str(ind)+\".png\"\n",
    "    filename_3 = 'rlsa_h_'+str(ind)+\".png\"\n",
    "    filename_4 = 'rlsa_v_'+str(ind)+\".png\"\n",
    "    filename_5 = 'rlsa_f_'+str(ind)+\".png\"\n",
    "    \n",
    "    denoised = make_denoised(imgArr,filepath_1,filename_1,params_denoise)\n",
    "    thres = apply_threshold(imgArr,filepath_2,filename_2,params_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_images/RLSA_h/'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 2\n"
     ]
    }
   ],
   "source": [
    "filepath_2 = \"test_images/threshold/\"\n",
    "\n",
    "thres_data = read_all_images(filepath_2, mode='binary')\n",
    "\n",
    "for ind,imgArr in enumerate(thres_data[1]):\n",
    "    filename_3 = 'rlsa_h_'+str(ind)+\".png\"\n",
    "    rlsa_h = perform_RLSA_hor(imgArr,filepath_3,filename_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 2\n"
     ]
    }
   ],
   "source": [
    "filepath_2 = \"test_images/threshold/\"\n",
    "\n",
    "thres_data = read_all_images(filepath_2, mode='binary')\n",
    "\n",
    "for ind,imgArr in enumerate(thres_data[1]):\n",
    "    filename_4 = 'rlsa_v_'+str(ind)+\".png\"\n",
    "    rlsa_v = perform_RLSA_ver(imgArr,filepath_4,filename_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 2\n",
      "Total_nos_images ==> 2\n"
     ]
    }
   ],
   "source": [
    "filepath_3 = \"test_images/RLSA_h/\"\n",
    "filepath_4 = \"test_images/RLSA_v/\"\n",
    "filepath_5 = \"test_images/RLSA_f/\"\n",
    "\n",
    "_,data_h = read_all_images(filepath_3,mode=False)\n",
    "_,data_v = read_all_images(filepath_4,mode=False)\n",
    "\n",
    "for ind in range(0,len(data_h)):\n",
    "    filename_5 = 'rlsa_f_'+str(ind)+\".png\"\n",
    "    get_RLSA_final(data_h[ind],data_v[ind],filepath_5,filename_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 2\n",
      "\n",
      "Applied dilation..\n",
      "\n",
      "Applied dilation..\n"
     ]
    }
   ],
   "source": [
    "_,data_rlsa = read_all_images(filepath_5, mode='binary')\n",
    "\n",
    "for ind in range(0,len(data_rlsa)):\n",
    "    apply_morphology(data_rlsa[ind], \"test_images/dilated/\", 'dilated_f_'+str(ind)+\".png\", ('dilation', 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 2\n"
     ]
    }
   ],
   "source": [
    "_,data_dil = read_all_images(\"test_images/dilated/\", mode='binary')\n",
    "original = copy.deepcopy(data)\n",
    "\n",
    "filepath_final = 'test_images/final_result'\n",
    "get_segments(data_dil, original, filepath_final, no_fill = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_nos_images ==> 2\n"
     ]
    }
   ],
   "source": [
    "_,data_dil = read_all_images(\"test_images/dilated/\", mode='binary')\n",
    "original = copy.deepcopy(data)\n",
    "\n",
    "filepath_final = 'test_images/final_result_1'\n",
    "get_segments(data_dil, original, filepath_final, no_fill = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
